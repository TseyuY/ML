# Ch2 模型评估与选择

## 2.1 经验误差与过拟合

> 把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”。
>
> 学习器在训练集上的误差称为“训练误差”或经验误差。
>
> 在新样本上的误差称为“泛化误差”。
>
> “过拟合”	“欠拟合”

## 2.2 评估方法

### 2.2.1 留出法

> 直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试机T，在S训练出模型后，用T来评估其测试误差，常见做法是将2/3~4/5的样本用于训练。

### 2.2.2 交叉验证法

> “交叉验证法”先将数据集D划分为k个大小相似的互斥子集(从D中分层抽样)每次用k-1个子集的并集作为训练集，余下那个子集作测试集，最终返回k组测试集的均值，评估结果的稳定性和保真性很大程度上屈居于k，又称为"k折交叉验证"，为减小因样本划分不同而引入的差别，通常要随机使用不同的划分重复p次，最终评估结果是这p次k折交叉验证结果的均值。
>
> 假定数据集D中包含m个样本，令k=m，则交叉验证为特例：留一法，缺陷在于数据集较大时。

### 2.2.3 自助法

> 由于保留了一部分样本用于测试，因此实际必然会引入一些因训练样本规模不同导致的估计偏差，留一法复杂度过高。
>
> 自助法：每次从D中挑选一个样本，拷贝放入D‘后放回，执行m次，得到D'，一部分样本多次出现一部分样本始终不出现，D'做训练集合D\D'用作测试集
>
> 自助法在数据集较小，难以有效划分训练/测试集时很有用，其产生的数据改变了初始数据集的分布，会一如估计偏差。